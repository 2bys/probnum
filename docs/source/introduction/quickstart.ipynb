{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ProbNum Quickstart\n",
    "\n",
    "ProbNum implements probabilistic numerical methods in Python. Such methods quantify _uncertainty arising from finite computation_ or from _stochastic input_.\n",
    "\n",
    "Below we explain how to get started with ProbNum and its basic functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make inline plots vector graphics instead of raster graphics\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('pdf', 'svg')\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.size'] = 18 \n",
    "plt.rcParams['text.usetex'] = True\n",
    "plt.rcParams['text.latex.preamble'] = [r'\\usepackage{amsfonts}', \n",
    "                                       r'\\usepackage{amsmath}', \n",
    "                                       r'\\usepackage{bm}']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "You can install ProbNum using `pip` (or `pip3`).\n",
    "```bash\n",
    "pip install probnum\n",
    "```\n",
    "If you prefer to use the latest version of ProbNum, install directly from GitHub instead.\n",
    "\n",
    "```bash\n",
    "pip install git+https://github.com/probabilistic-numerics/probnum.git\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Concepts\n",
    "\n",
    "The main objects of interest in ProbNum are random variables. `RandomVariable`s have a `Distribution` which models the (numerical) uncertainty on the variable in question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import probnum\n",
    "from probnum.prob import RandomVariable, Normal\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6243453636632417\n"
     ]
    }
   ],
   "source": [
    "x = RandomVariable(distribution=Normal(0, 1))\n",
    "print(x.sample())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RandomVariable`s behave similarly to NumPy arrays and support basic arithmetic, indexing and slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 1.0 and covariance: 4.0 of y.\n"
     ]
    }
   ],
   "source": [
    "y = 2 * x + 1\n",
    "print(f\"Mean: {y.mean()} and covariance: {y.cov()} of y.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic Numerical Methods\n",
    "\n",
    "PN methods solve numerical problems (e.g. solution of linear systems, quadrature, differential equations, ...) by treating them as _statistical inference problems_ instead.\n",
    "\n",
    "At a basic level they can serve as drop-in replacements for classic numerical routines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.12366738  1.28358209 -0.63965885]\n",
      "[-0.12366738  1.28358209 -0.63965885]\n"
     ]
    }
   ],
   "source": [
    "# Linear System Ax=b\n",
    "A = np.array([[7.5, 2.0, 1.0],\n",
    "              [2.0, 2.0, 0.5],\n",
    "              [1.0, 0.5, 5.5]])\n",
    "b = np.array([1, 2, -3])\n",
    "\n",
    "# Solve using NumPy\n",
    "x0 = np.linalg.solve(A, b)\n",
    "print(x0)\n",
    "\n",
    "# Solve using ProbNum\n",
    "x1, _, _, info = probnum.linalg.problinsolve(A, b)\n",
    "print(x1.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, probabilistic numerical methods return random variables instead of just numbers. Their distribution models the uncertainty arising from finite computation or stochastic input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.23355410e-01 -7.52102244e-01  7.23806730e-03]\n",
      " [-7.52102244e-01  2.53254571e+00 -2.43726653e-02]\n",
      " [ 7.23806730e-03 -2.43726653e-02  2.34557194e-04]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /home/j/.virtualenvs/probnum/lib/python3.8/site-packages/probnum/linalg/linearsolvers/matrixbased.py:518: UserWarning:Iteration terminated. Solver reached the maximum number of iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.08801172,  0.57079737, -0.63279916])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solve with limited computational budget\n",
    "x1, _, _, _ = probnum.linalg.problinsolve(A, b, maxiter=2)\n",
    "\n",
    "# Uncertainty in output\n",
    "print(x1.cov().todense())\n",
    "\n",
    "# Sample from output random variable\n",
    "x1.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the probabilistic linear solver has identified one component of the solution already with a high degree of confidence, while there is still some uncertainty about the others left due to the early termination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Prior Knowledge\n",
    "\n",
    "If we have prior knowledge about the problem setting, we can encode this into a PN method by specifying a prior distribution on the input. For this problem we observe that the matrix $A$ is symmetric. Additionally, suppose we are given an approximate inverse of the system matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.125  0.02   0.0275]\n",
      " [0.0325 1.025  0.01  ]\n",
      " [0.0275 0.005  1.07  ]]\n"
     ]
    }
   ],
   "source": [
    "# Approximate inverse of A\n",
    "Ainv_approx = np.array([[ 0.2  , -0.18, -0.015],\n",
    "                        [-0.18 ,  0.7 , -0.03 ],\n",
    "                        [-0.015, -0.03,  0.20 ]])\n",
    "print(A @ Ainv_approx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define prior distributions over $A$ and $A^{-1}$. Since there is no stochasticity in the problem definition we choose a highly concentrated symmetric prior over $A$. As a prior over the inverse we use the approximate inverse as a mean for the symmetric normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from probnum.linalg.linops import SymmetricKronecker, Identity\n",
    "\n",
    "# Prior distribution(s)\n",
    "A0 = RandomVariable(distribution=Normal(mean=A, \n",
    "                                        cov=SymmetricKronecker(10 ** -6 * Identity(A.shape[0]))))\n",
    "Ainv0 = RandomVariable(distribution=Normal(mean=Ainv_approx, \n",
    "                                           cov=SymmetricKronecker(0.1 * Identity(A.shape[0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00037817 0.0015451  0.00064998]\n",
      " [0.0015451  0.00631279 0.00265563]\n",
      " [0.00064998 0.00265563 0.00111716]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.14049052,  1.21484787, -0.66857357])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solve linear system with prior knowledge\n",
    "x1, _, _, _ = probnum.linalg.problinsolve(A, b, A0=A0, Ainv0=Ainv0, maxiter=2)\n",
    "\n",
    "# Uncertainty in output\n",
    "print(x1.cov().todense())\n",
    "\n",
    "# Sample from output random variable\n",
    "x1.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that after the same number of steps in our algorithm all components are approximately identified and the uncertainty in the output is much lower. \n",
    "\n",
    "_Remark:_ The reader familiar with linear solvers might recognize that the prior on the inverse plays a similar role to the preconditioner for classic linear solvers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "probnum_kernel",
   "language": "python",
   "name": "probnum_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
